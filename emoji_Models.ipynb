{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting emoji\n",
      "  Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m590.6/590.6 KB\u001b[0m \u001b[31m731.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: emoji\n",
      "Successfully installed emoji-2.14.1\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import emoji\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input,AveragePooling1D,Dense,Flatten,Embedding, LSTM, Bidirectional\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_dictionary = {\"0\": \"\\u2764\\uFE0F\",\n",
    "                    \"1\": \":baseball:\",\n",
    "                    \"2\": \":smile:\",\n",
    "                    \"3\": \":disappointed:\",\n",
    "                    \"4\": \":fork_and_knife:\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_emoji(label):\n",
    "    return emoji.emojize(emoji_dictionary[str(label)],language='alias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>never talk to me again</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am proud of your achievements</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It is the worst day in my life</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Miss you so much</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>food is life</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 0  1   2     3\n",
       "0           never talk to me again  3 NaN   NaN\n",
       "1  I am proud of your achievements  2 NaN   NaN\n",
       "2   It is the worst day in my life  3 NaN   NaN\n",
       "3                 Miss you so much  0 NaN   [0]\n",
       "4                     food is life  4 NaN   NaN"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir = '/home/milad/Desktop/python/AI/DL/Mini_project/db/emojify'\n",
    "df = pd.read_csv(f'{dir}/train_emoji.csv',header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,Y_train = df[0].values,df[1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(f'{dir}/test_emoji.csv',header=None)\n",
    "X_test,Y_test = test_df[0].values,test_df[1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((56,), (56,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape,Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is the worst day in my life üòû\n"
     ]
    }
   ],
   "source": [
    "index=2\n",
    "\n",
    "print(X_train[index],label_to_emoji(Y_train[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_oh=to_categorical(Y_train,5)\n",
    "Y_test_oh=to_categorical(Y_test,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_oh[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'never talk to me again'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('I am so impressed by your dedication to this project', 52)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(X_train,key=len),len(max(X_train,key=len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len=len(max(X_train,key=len).split())\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = '/home/milad/Desktop/python/AI/DL/Mini_project/db/glove.6B'\n",
    "embeddings_index = {}\n",
    "words_to_index = {}\n",
    "index_to_words = {}\n",
    "with open(f'{dir}/glove.6B.100d.txt',encoding = 'utf-8') as f:\n",
    "  lines = f.readlines()\n",
    "  words = set()\n",
    "  for line in lines:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    embed = values[1:]\n",
    "    weights = np.asarray(embed,dtype = 'float32')\n",
    "    embeddings_index[word] = weights\n",
    "    words.add(word)\n",
    "\n",
    "  i = 1\n",
    "  for w in sorted(words):\n",
    "    words_to_index[w] = i\n",
    "    index_to_words[i] = w\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def senetences_to_indices(X,word_to_idx,max_len):\n",
    "  m = X.shape[0]\n",
    "  X_indices = np.zeros((m,max_len))\n",
    "  for i in range(m):\n",
    "    sentence_words = X[i].lower().split()\n",
    "    for j,w in enumerate(sentence_words):\n",
    "      X_indices[i,j] = word_to_idx[w]\n",
    "  return X_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('I am proud of your achievements',\n",
       " array([185457.,  52943., 293982., 268046., 394565.,  45460.,      0.,\n",
       "             0.,      0.,      0.]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sequences = senetences_to_indices(X_train,words_to_index,max_len = max_len)\n",
    "X_train[1],X_train_sequences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrained_embedding_layer(embeddings_index,words_to_index):\n",
    "  vocab_len = len(words_to_index) + 1\n",
    "  emb_dim=embeddings_index['ali'].shape[0]\n",
    "  emb_matrix=np.zeros((vocab_len,emb_dim))\n",
    "  for word,index in words_to_index.items():\n",
    "    emb_matrix[index,:]=embeddings_index[word]\n",
    "  embedding_layer = Embedding(vocab_len,emb_dim,trainable=False)\n",
    "  embedding_layer.build((None,))\n",
    "  embedding_layer.set_weights([emb_matrix])\n",
    "  return embedding_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EmojifyModel(input_shape,embeddings_index,words_to_index,max_len=max_len):\n",
    "  sentence_indices = Input(input_shape,dtype = np.int32)\n",
    "  embedding_layer = pretrained_embedding_layer(embeddings_index,words_to_index)\n",
    "  embeddings = embedding_layer(sentence_indices)\n",
    "\n",
    "  x = AveragePooling1D(pool_size=max_len)(embeddings)\n",
    "  x = Flatten()(x)\n",
    "  x = Dense(5,activation='softmax')(x)\n",
    "  model = Model(sentence_indices,x)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 16:35:40.641299: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2025-02-16 16:35:40.641357: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2025-02-16 16:35:40.641396: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (milad-HP): /proc/driver/nvidia/version does not exist\n",
      "2025-02-16 16:35:40.642000: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-16 16:35:40.711408: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 160000400 exceeds 10% of free system memory.\n",
      "2025-02-16 16:35:41.066207: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 160000400 exceeds 10% of free system memory.\n",
      "2025-02-16 16:35:41.167057: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 160000400 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 10)]              0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 10, 100)           40000100  \n",
      "                                                                 \n",
      " average_pooling1d (AverageP  (None, 1, 100)           0         \n",
      " ooling1D)                                                       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 505       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,000,605\n",
      "Trainable params: 505\n",
      "Non-trainable params: 40,000,100\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 16:35:41.595917: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 160000400 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "model = EmojifyModel((max_len,),embeddings_index,words_to_index)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.5187 - accuracy: 0.3333\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.5156 - accuracy: 0.3333\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.5130 - accuracy: 0.3258\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.5106 - accuracy: 0.3182\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.5081 - accuracy: 0.3258\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.5062 - accuracy: 0.3333\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.5034 - accuracy: 0.3333\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.5005 - accuracy: 0.3712\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.4985 - accuracy: 0.3561\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.4962 - accuracy: 0.3636\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.4942 - accuracy: 0.3939\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.4922 - accuracy: 0.3864\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.4911 - accuracy: 0.3939\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.4900 - accuracy: 0.3712\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.4886 - accuracy: 0.3788\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.4869 - accuracy: 0.3864\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.4858 - accuracy: 0.3712\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.4846 - accuracy: 0.3788\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.4834 - accuracy: 0.3788\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.4815 - accuracy: 0.4015\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.4803 - accuracy: 0.4015\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.4788 - accuracy: 0.4091\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.4772 - accuracy: 0.4015\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.4765 - accuracy: 0.3939\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.4755 - accuracy: 0.4015\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.4741 - accuracy: 0.3939\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.4734 - accuracy: 0.3939\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.4727 - accuracy: 0.3864\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.4712 - accuracy: 0.4015\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.4703 - accuracy: 0.4091\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.4690 - accuracy: 0.4091\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.4684 - accuracy: 0.4091\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.4673 - accuracy: 0.4091\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.4662 - accuracy: 0.3939\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.4649 - accuracy: 0.4167\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.4640 - accuracy: 0.4091\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.4624 - accuracy: 0.4015\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.4615 - accuracy: 0.3939\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.4609 - accuracy: 0.3939\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.4599 - accuracy: 0.4015\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.4588 - accuracy: 0.4015\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.4577 - accuracy: 0.3939\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.4567 - accuracy: 0.3939\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.4563 - accuracy: 0.3939\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.4549 - accuracy: 0.3939\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.4540 - accuracy: 0.3939\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.4532 - accuracy: 0.4015\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.4523 - accuracy: 0.4015\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.4509 - accuracy: 0.3939\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.4501 - accuracy: 0.4015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x78677d5270a0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_sequences,Y_train_oh,epochs=50,batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 127ms/step\n",
      "I am happy üòÑ\n",
      "not feeling happy üòÑ\n",
      "i want to die üòû\n"
     ]
    }
   ],
   "source": [
    "x_test = np.array(['I am happy','not feeling happy','i want to die'])\n",
    "x_test_indices = senetences_to_indices(x_test,words_to_index,max_len)\n",
    "pred = model.predict(x_test_indices)\n",
    "\n",
    "for item,label in zip(x_test,pred):\n",
    "  print(item,label_to_emoji(np.argmax(label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Emojify_V2(input_shape,word_to_vec_map,word_to_index):\n",
    "  sentence_indices = Input(input_shape,dtype = np.int32)\n",
    "  emb = pretrained_embedding_layer(word_to_vec_map,word_to_index)\n",
    "  embeddings = emb(sentence_indices)\n",
    "\n",
    "  X = LSTM(64,return_sequences=True)(embeddings)\n",
    "  X = LSTM(64)(X)\n",
    "  X = Dense(5,activation='softmax')(X)\n",
    "\n",
    "  model = Model(sentence_indices,X)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 16:39:44.721368: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 160000400 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "model2 = Emojify_V2((max_len,),embeddings_index,words_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 10)]              0         \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 10, 100)           40000100  \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 10, 64)            42240     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,075,689\n",
      "Trainable params: 75,589\n",
      "Non-trainable params: 40,000,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5/5 [==============================] - 7s 23ms/step - loss: 1.5980 - accuracy: 0.3106\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.5188 - accuracy: 0.3561\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.4621 - accuracy: 0.3712\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.4080 - accuracy: 0.4015\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.3264 - accuracy: 0.5000\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.2494 - accuracy: 0.5152\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.1257 - accuracy: 0.5758\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.0004 - accuracy: 0.6515\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.8503 - accuracy: 0.6894\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.7460 - accuracy: 0.7652\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.6425 - accuracy: 0.8333\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.5833 - accuracy: 0.8106\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5369 - accuracy: 0.8409\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.4648 - accuracy: 0.8561\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4377 - accuracy: 0.8636\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.4544 - accuracy: 0.8636\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.4544 - accuracy: 0.8485\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.4890 - accuracy: 0.8030\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.3395 - accuracy: 0.9318\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.2430 - accuracy: 0.9545\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.2873 - accuracy: 0.9091\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.2151 - accuracy: 0.9621\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.1463 - accuracy: 0.9621\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.1735 - accuracy: 0.9545\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.1020 - accuracy: 0.9848\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0986 - accuracy: 0.9773\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0724 - accuracy: 0.9924\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0646 - accuracy: 0.9924\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0496 - accuracy: 0.9924\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0448 - accuracy: 0.9924\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0384 - accuracy: 0.9924\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0367 - accuracy: 0.9924\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0311 - accuracy: 0.9924\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0291 - accuracy: 0.9924\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0504 - accuracy: 0.9848\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0232 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0247 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0162 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0154 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0153 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0118 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0103 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0084 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0073 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0054 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x78677c112110>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train_sequences,Y_train_oh,epochs=50,batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step\n",
      "I am happy üòÑ\n",
      "not feeling happy üòÑ\n",
      "i want to die üòû\n"
     ]
    }
   ],
   "source": [
    "x_test = np.array(['I am happy','not feeling happy','i want to die'])\n",
    "x_test_indices = senetences_to_indices(x_test,words_to_index,max_len)\n",
    "pred = model.predict(x_test_indices)\n",
    "for item,label in zip(x_test,pred):\n",
    "  print(item,label_to_emoji(np.argmax(label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Emojify_V3(input_shape,word_to_vec_map,word_to_index):\n",
    "  sentence_indices = Input(input_shape,dtype=np.int32)\n",
    "  emb = pretrained_embedding_layer(word_to_vec_map,word_to_index)\n",
    "  embeddings = emb(sentence_indices)\n",
    "\n",
    "  X = Bidirectional(LSTM(64,return_sequences=True))(embeddings)\n",
    "  X = Bidirectional(LSTM(64))(X)\n",
    "  X = Dense(5,activation='softmax')(X)\n",
    "\n",
    "  model = Model(sentence_indices,X)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 10)]              0         \n",
      "                                                                 \n",
      " embedding_2 (Embedding)     (None, 10, 100)           40000100  \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 10, 128)          84480     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 128)              98816     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,184,041\n",
      "Trainable params: 183,941\n",
      "Non-trainable params: 40,000,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3 = Emojify_V3((max_len,),embeddings_index,words_to_index)\n",
    "model3.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5/5 [==============================] - 11s 29ms/step - loss: 1.6025 - accuracy: 0.2500\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.4874 - accuracy: 0.4015\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 1.4136 - accuracy: 0.4924\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 1.3114 - accuracy: 0.5758\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 1.2047 - accuracy: 0.5909\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 1.0395 - accuracy: 0.7424\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.8610 - accuracy: 0.7273\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.7570 - accuracy: 0.7500\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.5717 - accuracy: 0.8333\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.4728 - accuracy: 0.8485\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.3780 - accuracy: 0.8561\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.2921 - accuracy: 0.8939\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.2080 - accuracy: 0.9167\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.1684 - accuracy: 0.9394\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.1196 - accuracy: 0.9545\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0828 - accuracy: 0.9773\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0604 - accuracy: 0.9773\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0487 - accuracy: 0.9848\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0320 - accuracy: 0.9924\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0199 - accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0116 - accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.8717e-04 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.3772e-04 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 8.8884e-04 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 8.5032e-04 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 8.1205e-04 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7.8265e-04 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7.5288e-04 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7.2402e-04 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 6.9508e-04 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 6.6942e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x786775566c50>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(X_train_sequences,Y_train_oh,epochs=50,batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step\n",
      "I am happy üòÑ\n",
      "not feeling happy üòÑ\n",
      "i want to die üòû\n"
     ]
    }
   ],
   "source": [
    "x_test = np.array(['I am happy','not feeling happy','i want to die'])\n",
    "x_test_indices = senetences_to_indices(x_test,words_to_index,max_len)\n",
    "pred = model.predict(x_test_indices)\n",
    "for item,label in zip(x_test,pred):\n",
    "  print(item,label_to_emoji(np.argmax(label)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
